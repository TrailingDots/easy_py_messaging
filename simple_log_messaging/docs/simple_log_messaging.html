<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
    <head>
        <title>Simple Log Messaging: Distributed Logs for Raspberry Pi</title>
        <script src="./javascript/toc.js" type="text/javascript"></script>
        <link rel="stylesheet" href="css/article.css" type="text/css" />
    </head>

    <body onload="generateTOC(document.getElementById('toc'));">

        <h1>Simple Log Messaging</h1>

        <div id="toc"></div>


        <h2>Benefits of Simple Log Messaging</h2>

        <center>
        <div style="width:300px;border:1px solid #cecece; padding:10px;">
            <blockquote>It turns out that bulding reusable messaging systems
            is really difficult, which is why few free and open source
            (FOSS) projects ever get tried, and why commercial
            messaging products are complex, inflexible and brittle. ...
            It takes weeks to learn to use it, and months to create
            stable architectures that don't crash when things get
            hairy.</blockquote>
            <div class="credit" style="text-align:center;">
                <cite><a href="http://zguide.zeromq.org/page:all#Why-We-Needed-ZeroMQ">Pieter Hintjens in ZeroMQ</a></cite>
            </div>
        </div>
        </center>

        <p>This package strives to provide a simple, useful package for
        small projects. The learning curve should require only a minimal
        amount of python coding to produce acceptable results.</p>

        <p>This simple log messaging package offers a first installment for a
        succession of future package specifically targeting implementors of
        Raspberry Pi, Arduino, etc. boards: a name server and a control
        service. Managing multiple nodes should be easy.</p> 

        <p>By writing a wrapper on the industry standard ZeroMQ messaging
        library, logging gains significant enhancements from the existing
        python logging module. The ZeroMQ messaging system works well within a
        single process, between mulitple processes within a single system and,
        most importantly, with distributed nodes over a network.</p>

        <p>This code provides a solution to centralizing logs from multiple
        nodes.  With the inevitable rise of distributed systems 
        everywhere, a centralized log offers an in-depth view for
        problem solving.</p>

        <p>Developers face a quandry when faced with inevitable problems.
        Developers can greatly simplify their efforts in understanding
        and discovering solutions by taking time to implement a
        reasonable logging philosophy.</p>

        <p>Logs have been around as long as computers and form the
        core of many distributed and real-time applications. Logs
        form <i>the</i> way to debug live systems. Without some form
        of logging, how can anyone gain insight into significant
        problems?</p>

        <p>Distributed computing rely on logs to maintain a useful view of
        both hardware and software. As a cross cutting concern, logging remains
        along with security a necessity for modern systems.</p>
        
        <h2>Specifically Targeted: Logging Raspberry Pi Systems</h2>

        <p>As the price of credit card sized computers and their associated
        instrumenteation continues to fall, distributed systems will continue
        to proliferate.  Connecting these systems together raises problems of
        debugging and tracking. Logging supplies a significant contribution
        towards a viable solution.</p>
        
        <p>Once a Raspberry Pi system has been installed and starts working,
        new and different ideas frequently require both software and hardware
        upgrades. Perhaps some of these upgrades would be easier with the
        addition of another Raspberry Pi system? This could hold especially
        true for those creations involving hardware expansion. The existing
        system works fine, but upgrades threaten the stability of the existing
        system. After all, you've likely expended a significant effort.</p>

        <p>Consider implementing another Raspberry Pi system for those
        enhancements. As even more ideas pop up, could a convenient way to
        expand involve adding even more Raspberry Pi systems? With the cost of
        hardware dropping dramatically, how much effort would you care to
        devote to integrating those changes in software? If you are like most
        people, upgrading software can represent a serious investment of both
        time and money. How much easier would a new Raspberry Pi board
        represent?<p>

        <p>Suppose your home automation system has been growing. You started
        with the interior of your house. Now you want to expand to your
        backyard and perhaps even to your front yard. Are three system on the
        horizon? One for the interior, one for the front and one for the back?
        What about one system to rule them all? Do you relish running all that
        new wiring when those boards could use wifi instead? Or have you become
        so device crazy that the GPIO cannot handle all those inputs and you
        <i>must</i> use more systems.</p>

        <p>Another example would be that hydroponics system that has started to
        function well. You've spent a fair amount of time and now you want
        another system with new ideas implemented from lessons on the original
        prototype.  The existing system works fine, so changing it has little
        appeal: "If it ain't broke, don't fix it!" The new system, however, can
        absorb all that new hardware and software that's been bubbling though
        your mind.</p>

        <h2>The Primary Goal</h2>

        <p>This application offers a logging server capable of collecting
        logs from multiple sources and storing them into a text file or
        database system. The initial release saves only to a text file.</p>

        <p>The primary goal supplies a useful and <i>easy</i> to use logging
        system that will work well with supplied enhancements for controlling
        and monitoring distributed Raspberry Pis, Arduinos or similar systems.
        This package provides general purpose software capable of providing
        solid logging capabilitiies for almost any system supporting python and
        ZeroMQ!</p>


        <h1>Benefits of Logging</h1>

        <p>Benefits of logging frequently become vastly underestimated
        in the course of developing and debugging systems.</p>

        <p>This logging package provides a simple way to embed
        powerful logging techniques into your systems.</p>
        
        <p>This package was designed to provide logging for:</p>

        <ul>
            
            <li>A single stand-alone process.  If the application gets
            refactored into multiple proceses, this logging package provides a
            common channel for logging.</li>

            <li>Handling logging for multiple processes on a single
            system. The processes use this package to conveniently
            record timestamped information on the behavior of each
            process.</li>

            <li>Distributed systems. This paackage really shines
            in this area. The resulting logs correlate the actions
            of multiple systems and provides a single repository
            of information for analysis.</li>

        </ul>

        <p>Logging can provide substantial benefits for both developers and
        users.  The fact that developers remain mostly unaware of these
        benefits presents problems. Proper logging can ease a wide variety of
        problems.</p>

        <p>Few programmers appreciate the benefits of logging.  Even fewer
        consider how logging can ease their burdens in finding and solving
        problems on both development and live systems.</p>

        <p>Benefits to users similarly get short shrift. Users require
        insights into their systems that logging can frequently provide.
        Informed developers implement user oriented logging as a natural
        course of action.</p>

        <p>Observing behavior in a distributed system presents a problem. Do
        pumps operate on schedule? How about maintaining water levels?  Does
        the lighting operate as scheduled? Does the temperature remain within
        range? If something goes wrong, how long until your notice that
        problem? And, more importantly, how do you debug that misbehaving
        system?</p>

        <p>Logging offers a major opportunity to observe all this
        and more.</p>

        <p>Good, really good logging remains an elusive target.  Most
        developers seem content with either the bare minmum or with flooding a
        system with lots and lots of useless debug garbage.</p>

        <p>Proper logging of a running process provides <i>the</i>
        primary view into your running proceses. Without this
        log view only guessing remains.</p>

        <p>Debugging distributed systems can provide hours of frustrating
        entertainment. A clatch of logs supplies nutritious food for forensic
        debugging.</p>


        <p>Did I say logging as a debugging tool in development? Why yes,
        I did.</p>

        <h2>Still Using Print Statements?</h2>

        <p>Many noobies seem satisfied with the ubiquitous "print" statements.
        Their console output becomes cluttered with tons of disorganized,
        unfiltered, opaque output.</p>

        <p>The lowly "print" statements cannot work outside the narrow confines
        of brief ad-hoc debugging. Print statements for debugging clutter both
        code and console output. They cannot become a permanent feature of your
        application.</p>


        <h2>Logging within a Single System</h2>

        <p>The logging solution extends beautifully to multiple
        systems. However, a single system
        cannot use logging to great advantage. Starting with
        a single system with easy logging greatly simplifies
        expansion to larger systems. That single system can become a
        wealth of information for further implementations.</p>

        <p>The proposed simple log messaging app solution can even live as a
        thread within a single process! The degree of flexibility offered along
        with ease of implementation allows this solution to shine!</p>

        <h2>Using the Simple Log Messaging Application</h2>

        <p>The simple log messaging application greatly eases the problem of
        tracking what happens in your SOC systems. It provides a central
        logging system that collects logs from one or more application and
        stores them into either a simple text file or a database. The messaging
        speed has been demonstrated to be adequate for all but the most
        demanding applications.</p>

        <p>The API has been simplified so that even noobies should not have
        trouble in using the code. Only one IP address and one port need be
        specified.</p> 

        <p>The process generating the logs can reside on the same node as the
        logger.  Alternatively the process creating the logs can run on a
        system removed from the logging system.</p>

        <p>A separate logging process presents a much stronger resource than a
        thread of the application task. If the application were to crash, the
        last few logs may be buffered and lost in the crash.  If a separate
        logging task would used, it would receive those last few logs and post
        them to your logging repository.</p>

        <p>This local vs. remote flexibility opens the possibility of storing
        logs on a desktop in your home while monitoring SOC computers in your
        garden, backyard, garage or other places of interest. The remote
        systems could crash and the logging system will assist in debugging
        that crash. Your crashed system may or may not have information
        necessary to fixing that crash.</p>

        <p>As the various parts of the RaspPiLogging system are presented, the
        necessary debugging techniques will also be explained. When I am
        learning a new system and attempting to follow the steps for installing
        or implementing that system, I notice that the authors usually ignore
        problems. The just assume everything will work.  In these situations I
        am always wondering, "How do I verify that this is correct?"</p>


        <h1>Introductory Matters</h1>

        <h2>Python as an Implementation Language</h2>

        <p>Because Python has demonstrated global acceptance for many projects
        on our tageted boards, the simple log messaging app will continue this
        tradition. Python provides an easy-to-code implementation language as
        well as convenient debugger support. This project combines the power of
        ZeroMQ to create a powerful logging system.</p>

        <h2>Audience</h2>

        <p>We assume the reader has one or more systems such as Raspberry Pi,
        Arduino or BeagleBoard. Additionally, a desktop system running Debian
        or Ubuntu or any linux system will ease development because desktop
        systems typically have greater capablities such as disk space, memory,
        speed, and multiple monitors. </p>
        
        <p>Developing an application using a single Raspberry Pi system also
        works well.</p>

        <p>Some python knowledge is assumed. Intermediate to advanced noobies
        can use this code while absolute beginners will likely struggle.
        Certainly advanced programmers should expect only minor issues.</p>

        <h2>Original Hardware Development</h2>

        <p>This code was originally developed on a Linux Centos 7 system.
        It was tested on Raspberry Pi B 2 boards running the Raspian Debian OS
        with 8Gb SSD and 512Mb RAM. The testing between boards used the
        USB wireless ports on the Raspberry Pi hardware. Frequently
        the Raspberry Pi boards communicated with the Centos 7 system as a
        logging collection server.</p>

        <h2>Getting the Code</h2>

        <p>The application source code resides at: <a
            href="https://gitlab.com/TrailingDots/loggerZeroMQ.git">loggerZeroMQ</a>.
        The code should work on any recent linux system and will work on a
        recent Raspberry Pi Raspian OS. The Raspberry Pi Logger has been built
        on a Raspian OS and a Centos 7 Linux system. Unbuntu and Debian OSs
        should allow for an easy build. No attempt has been made for Windows
        versions.</p>


        <h1>Installation</h1>

        <p>If there are any problems, consult the Troubleshooting section.</p>

        <p>Each of the following commands may require a <code>sudo</code>
        in front of the command to allow root to install in secure
        locations.</p>

        <p>If the results of a <code>pip</code> command results in
        "Requirements already satisfied...", upgrade to the latest version by
        supplying the <code>--upgrade</code> switch as in: <code>pip install
        --upgrade cython</code> .

        <ul>

            <li>Install the <a href="http://zeromq.org/area:download#toc5">ZMQ C libraries</a>.
            Alternatively, a download of binaries should work equally well. <a href="zeromq.org">ZeroMQ</a> has detailed procedures for installation if necessary.</li>

            <li>Install <a
            href="https://github.com/zeromq/pyzmq.git">PyZMQ</a>,
            the python bindings to ZeroMQ.</li>

        </ul>

        <p>ZeroMQ should exist and python code should work with ZeroMQ,
        Test this by:</p>

        <pre >
        python
        import zmq</pre>

        <p>If errors get emitted, please refer to the web for
        workarounds.</p>

        <p>Continue to install the simple_log_messaging code:</p>


        <p><code>cd</code> to a directory to work from.</p>

        <p>Install the simple log messagng application: <br/>
        <code class="indent">git clone
            https://github.com/TrailingDots/simple_log_messaging.git</code><br/>
        If you get "permission denied", then you need to prefix the
        previous command with <code>sudo</code> to install with root
        access.</p>

        <p>Move into the just-downloaded code:<br/>
        <code class=indent>cd
            simple_log_messaging</code></p>

        <p>Finish the installation with a final install:<br/> <code>python
            setup.py install</code> Again, if "permission denied", prefix with
        "sudo"</p>
        
        <p>Ensure the logCollector has been installed:<br/>
        <code class=indent>which
            logCollector</code><br/>If you get an error containing something
        like "<code>no logCollector in ...</code>, refer to the troubleshooting
        section.</p>

        <p>Start the log Collector: <br/>
        <code class=indent>logCollector
            --log-file=/tmp/xyz.log</code><br/>
        This will create logs in /tmp/xyz.log.</p>

        <p>In another terminal window, send a log: <br/>
        <code class=indent>logCmd Simple
            test</code></p>

        <p>Examine the log in /tmp/xyz.log:<br/> 
        <code class=indent>cat /tmp/xyz.log</code><br/>
        <code class=indent>2016-04-14T13:49:19.851
            INFO	Simple test,host=brass</code><br/> The timestamp reflects
        only the time this log was received and the host signifies your current
        hostname.</p>

        <p>Congratulations! You have a working system!</p>


        <h1>Supplied Tools</h1>

            <h2>logCollector - Collecting and saving log messages</h2>

            <p>The process that collects logs sent from other threads
            and/or processes. Logs currently get saved in simple text
            files.</p>

            <pre>
logCollector --help
logCollector: pid 18083, port 5570
logCollector [--log-file=logFilename] [-a] [-t]
     logFilename = name of file to place logs
     -a  Logs will be appended to logFilename. Default
     -t  logFilename will be truncated before writing logs.

-a and -t apply only when --file specifics a valid filename.
--noisy or -n : Echo message to console. Useful for debugging.
If logFilename does not exist, it will be created

logCollector [--help]
     This message

To toggle printing of messages received:
    kill -USR1 &lt;pid&gt;
            </pre>

            <ul>

            <li><code>-log-file=&lt;filename&gt;</code> - The filename where
            logs will get saved. Using an absolute filename provides assurity
            that the files get stored in a well known place.  Caveats such as
            an existing directory and permissions apply, of course.</li>

            <li><code>-a</code> - New logs should normally get appended to the
            end of any existing logs. This is the default.</li>

            <li><code>-t</code> - Any existing log-file gets truncated and all
            new logs will replace the existing log file. Sometimes useful when
            debugging a system.</li>

            <li><code>--help</code> - The help display.</li>

            </ul>

            <h3>Configuration file</h3>

            <p>In normal operations the logCollector begins by reading a
            configuration file from <code>.logcollectorrc</code>. If that file
            does not exist, it tries to read
            <code>$HOME/.logcollectorrc</code>, that is, the configuration file
            from the user's home directory.</p>

            <p>Users may, of course, supply a configuration filename on
            the command line with the <code>--config=&lt;filename&gt;</code>
            argument.</p>

            <p>The configuration file eases the implementation of more
            complex systems by storing any special setting necessary.</p>

            <p>The default contents of <code>.logcollectorrc</code>:</p>

            <pre>
{
    "append":   True,
    "out_file": './logs.log',
    "noisy":    False,
    "port":     5570,
}
            </pre>

            <ul>

                <li>append - True to append new logs to the tail of
                any existing logs. This satisfies most normal requirements.</li>

                <li>out_file - The name of the output log file. This should typically 
                use an absolute filename. Any relative filename will
                write logs relative to the directory where logCollector
                was started.</li>

                <li>noisy - Logs do not normally get echoed to the console.
                However, while debugging a system, listing all incoming logs
                to the console as well as to the out_file provides a
                convenient monitoring scheme.</li>

            </ul>

            <p>An additional feature to the <code>noisy</code> config option is
            the command line option to toggle <code>noisy</code> as required.
            When logCollector starts, it displays the process id, pid, of
            itself. In the help message above this was 18083.  To toggle
            console display of log messages, send the command <code>kill -USR1
            18083</code>. This has been found useful in debugging a system. The
            only trick has been in remembering the pid of logCollector.</p>

            <h2>logFilterApp - Assistance in log interpretation</h2>

            <p>This command line utility program converts from the the standard
            log format to either JSON or CSV. JSON remains the preferred
            format.</p>

            <p>Given a repository of logs, what is the difficulty of
            discovering problems in logs of several thousand entries? How
            would you handle that mind numbing experience? Now repeat that same
            experience over and over when necessity dictates various queries of
            those logs. Now consider that enterprise systems typically
            contains log files of million or even billions of logs?</p>

            <p>Various log analysis tools exist to select and interpret log
            files. This initial release contains an elementary analysis tool
            that can output logs in either CSV (Comma Separated Values) or JSON
            (JavaScript Object Notation).  CSV conveniently loads into
            almost any spreadsheet. JSON offers ease of loading into
            most modern programming languages: python, NodeJS, JavaScript,
            etc.</p>

            <pre>
logFilterApp [--out-file=outfile] [--in-file=infile]
	[--start=&lt;ISO8601 start date&gt;] [--end=&gt;iso8601 end date&gt;]
	[--JSON | --CSV] 
    [--help]
	[--level=&lt;level name&gt;] 
    [--out-file=output file] # output goes here. Default: stdout
    [--in-file=input file]   # input file here. Default: stdin

--start=&lt;iso8601 start date&gt;     # start date iso formatted
--end=&lt;iso8601   end   date&gt;     # end   date iso formatted
 If start with no end, continue to present time.
--level=LEVEL   # Handle only from LEVEL up.
 DEBUG,CMD,INFO,WARNING,ERROR,CRITICAL are the levels.
--JSON          # output format is JSON (default)
--CSV           # Output format is CSV
--help          # This message
            </pre>

            <ul>

                <li><code>--out-file=filename</code> - The name of an
                output file to place the results. Output files format
                themselves as either JSON or CSV. The console is the
                default output.</li>

                <li><code>--in-file=log_filename</code> - The name of
                the logfile to use as input. The console is the default.</li>

                <li><code>--start=&lt;ISO8601 start date&gt;</code> - An ISO8601
                    formatted date to begin filtering log data. See the section
                    below on ISO8601 dates.</li>

            <li><code>--end=&lt;ISO8601 end date&gt;</code> - An ISO8601
            formatted date to stop filtering log data. See the section
            below on ISO8601 dates.</li>

            <li><code>--JSON</code> - The output format is JSON format.
            JSON provides an easily read coding format
            for almost all languages. JSON is the default format.</li>

            <li><code>--CSV</code> - The output format is CSV, Comma
            Separated Variables. Speadsheets can easily consume
            this information. CAREFUL: The log files must have
            been carefully formatted to intelligently produce
            CSV. JSON is the default format.</li>

            <li><code>--level=&lt;level&gt;</code> - Only log entries
            at or above this level get processes. The default
            level is WARNING, meaning only WARNING, ERROR and
            CRITICAL log entries appear in the output.</li>

            <li><code>--help</code> - The help message.</li>

        </ul>
                

        <h3>A note on start and end dates</h3>

        <p>The default start and end dates are from the start of
        the log file to the end of the log file. This default
        gets used when no dates are specified. For larger log
        files this may yield abnormally large output files.</p>

        <p>Supplying a start date only results in ignoring log
        entries before the specified date. The remainder of the log
        file gets processed. A common use would be reading today's
        logs.</p>

        <p>Suppling an end date only will read from the beginning
        of the log file upto and including the end date.</p>

        <p>Supplying both a start and end date will, of course,
        read all logs between these two dates. Gathering information
        on last weeks operations could be a typical case.</p>
            
        <h3>Configuration Files</h3>

        <p>Filtering log entries can result in powerful analytics
        for your system. Depending up your needs, various
        scenarios present themselves over and over.</p>

        <p>Perhaps the solution to handle these repetitious queries
        represents itself in a configuration file.  Using multiple
        configuration files allows easy invocation of multiple queries.</p>

        <p>The logFilterApp configuration file contains a python
        dictionary of matching keyword=values the same as
        described in the help output above. Due to "standard"
        linux nameing conventions, the configation file
        uses '_' instead of '-'.</p>

        <p>A sample configuration file to read every log entry
        for all times with a level of <code>CMD</code> and above:</p>

        <pre>
cat $HOME/cmd.conf  # List the config file.
{
'in_file': 'data/base.data',
'level': 'CMD',
}
        </pre>

        <p>Notice the absense of start and end times. The default
        start time means the start of the Linux epoch. The default
        end time means now. Thus, the entire contents of the
        file will be read.</p>

        <p>But what if all  you need is a single day's worth of
        logs? When a configuration file gets loaded, further
        command line arguments override existing arguments. For
        example, if you were working on your taxes Apr 15,2016,
        you could use this configuration file to read data only for
        Apr 15, 2016:</p>

        <pre>
logFilterApp --config=$HOME/cmd.conf --start=2016-04-15T00:00:00.000 --end=2016-05-15T23:59:59.000
        </pre>

        <h3>Supplying your own log filters - TBD</h3>

        <p>The current filtering allows powerful results. But what if
        your requirements were more extensive? What if you needed to
        search for an <code>ERROR</code> and process related logs?
        The current filtering does not allow easy management of such
        requests.</p>

        <p>TBD - A placeholder exists in the code for this!</p>


        <h2>logCmd - Simple logging for shell commands</h2>

        <p>logCmd fills the need to log information from the
        linux shell. Either the console or shell scripts may
        send logs to the logCollector.</p>

        <p>Using logCmd is simplicity itself:<br/><code class=indent>
            logCmd This is an important message</code><br/>
        The string "This is an important message" get appended
        to the existing logs.<p>

        <p>When using logCmd pay attention to the format. The
        command line arguments get sent as the are written.
        If the arguments can be free-form, meaning literally
        anything, then just start typing.</p>

        <p>If the arguments contain data that may be processed later by
        something like logFilterApp, take care to write a proper parsable
        string. For instance, suppose a shell script reads a
        temperature. This could be sent as:<br/><code
        class=indent>logCmd therm01=74.6</code></p>

        <p><b>WARNING!</b> logCmd will hang unless the logCollector
        process is running. logCmd does not attempt to determine
        if a logCollector is running because multiple logCollectors
        may be run on different ports. Also, the code for this
        utility has been deliverately left as simple as possible.<p>

        <p>See an explanation of logCmd and its coding as
        a simple example of using simple log messaging in
        your own code.</p>

        <h2>loggingLoopApp - For debugging your logging system</h2>

        <p>In the process of development the requirement may arise
        to repeatedly send logs. Problems in communications, configuration
        file mis-configured, path problems in finding programs,
        downed boards, disconnected wiring, etc.</p>

        <p>The current implementation send a logs once a second to
        logCollector. The log contents provide feedback of
        successful messaging and little else.</p>

        <p>To run this utility, use a two console: one for collecting
        the logs and one for loggingLoopApp. These terminals may
        be on the same system or on different systems.</p>

        <p>Start the logCollector:<br/><code class=indent>logCollector --noisy</code></p>

        <p>On the other terminal start sending log messages:<br/><code>loggingLoopApp</code></p>

        <p>The terminal running loggingLoopApp will list something similar
        to:</p>

        <pre>
python loggingLoopApp.py
&gt;&gt;&gt; loggingApp: pid 5413
loggingApp: Client worker-RaspPi5413 started
Req #0 sent "request #0"
Req #1 sent "request #1"
Req #2 sent "request #2"
        </pre>

        <p>And the console where logCollector reports:</p>

        <pre>
2016-04-20T11:07:21.180	DEBUG	request #0,host=worker-RaspPi5413
2016-04-20T11:07:22.181	DEBUG	request #1,host=worker-RaspPi5413
2016-04-20T11:07:23.183	DEBUG	request #2,host=worker-RaspPi5413
        </pre>

        <p>The timestamp and worker ID will, of course, be different.</p>

        <p>Kill both the loggingLoopApp and logCollector with 
        ctrl-C in each terminal.</p>

        <h2>listeningPort - Detecting a logCollector</h2>

        <p><b>WARNING!</b> This utility may not work on all systems!  If
        this procedure does not work on your system, refer to <a
        href="http://www.cyberciti.biz/faq/what-process-has-open-linux-port/">Linux:
    Find Out Which Process Is Listening Upon a Port</a>. Sorry, I
        tried!</p>

        <p>Many times when developing software manual testing
        requires repeating the same process over and over.
        Due to various factors, it's easy to forget that
        the logCollector process already runs. It's certainly
        possible to forget the exact terminal logCollector runs
        on. listeningPort provides an answer to this situation.</p>

        <p>This utility must be run on the same node that logCollector
        runs.</p>

        <pre>
listeningPort --help

Give a port that defaults to ZeroMQ of 5570,
list the processes that are listening to that port.

Use by:
  listening [--help] [--short] &lt;port&gt;
e.g.:
  listening 5570      # The ZeroMQ default port
--help = this message
--short = Output consists of only three space separated fields:
    &lt;port&gt; &lt;pid of listener&gt; &lt;process name of listener&gt;

Return codes:
  0 = Nobody listening to &lt;port&gt;
  1 = Someone is listening. stdout has details.
        </pre>

        <ul>

            <li><code>--help</code> - Provide help message.</li>

            <li><code>--port=port_number</code> - Use port_number
            for the logCollector.</li>

            <li><code>--short</code> - Output displayed in a condensed
            manner. Three fields get separated by spaces:<br/>
            <code>&lt;port&gt; &lt;pid of listener&gt; &lt;process name of
            listener&gt;</code><br/>This permits ease of processing by
            shell scripts or programs.</li>

        </ul>

        <p>Start <code>listeningPort</code> on some terminal. The response
        will be one of two possible output: (Of course, your pids will differ)</p>

        <pre>
# logCollector is running
listeningPort
Port 5570 : listening thru pid 5933 named /home/cecilm/.local/bin/logCollector
        </pre>

        <pre>
# logCollector is not running, or it may be running on a different port.
listeningPort
Port 5570 : Nobody listening
        </pre>


    <h1>Sample Code</h1>
    
    <p>In all the following example the logCollector must run. The
    logCollector process listens to the designated ZeroMQ port and
    save the incoming logs to a text file. This file may be read with
    any editor.</p>

    <p>Installation should have installed logCollector in a location
    within your $PATH environmental variable.</p>

    <h2>Shell Logging: logCmd</h2>

    <p>Perhaps the simplest logging consists of a single command
    from a terminal. Shell commands provide a convenient way to
    record significant events of functioning systems. The code for
    <code>logCmd</code> also provides convenient tutorial for the
    use of the simple log messaging tools.</p>

    <p>The code that implements logCmd:</p>

    <pre>
import sys
import platform
import logging
import loggingClientTask

def main():
logging.basicConfig(level=logging.NOTSET)   # Log everything
client = loggingClientTask.LoggingClientClass(platform.node())
client.start()

msg = ' '.join(sys.argv[1:])
client.info(msg)
    </pre>

    <p>The first three lines of <code>main()</code> contain
    all needed information to send a log to the collector with
    a level of <code>info</code>. The first line overrides
    any possible setting that eliminate <code>info</code>
    level logs. The next two lines create and start a logging
    process.</p>

    <p>Since a logging process has been started, an arbitary
    number of logs could be sent. However, the last two lines
    space separate the command line argumens and send to
    logCollector.</p>

    <h3>Exercise: Expand upon logCmd</h3>

    <p>Very simple code indeed. But this code could be a skeleton for
    much more complex applications.</p>

    <ul>

        <li>The original code uses the pre-configured logConfig
        for port addresses. Add a command line option that
        allows the user to specify a port. This will, of course,
        require adding a <code>usage()</code> routine
        as part a new <code>--help</code> option as well.</li>

        <li>The current code uses the <code>INFO</code> log level
        for recording logCmd entries. Allow the user to
        specify the level at run time. This permits a shell
        to log <code>ERROR</code>, <code>WARNING</code>, etc.</li>

    </ul>

    <h1>Tips for Great Logging</h1>

    <p>Even in our simple Raspberry Pi hydroponic system, a bit of thought
    placed into logging concepts will absolutely serve us well. Just
    logging for logging sakes does not provide an incentive to log. Having
    these logs provide a usable history and alarm system incentivises our
    logging structure.</p>

    <p>Think of logging as an integral part of our SCADA system.  SCADA =
    Supervisory Control and Data Acquisition.  SCADA gets used in remote
    monitoring and control systems that operates with coded signals over
    communications channels. <a href="https://en.wikipedia.org/wiki/SCADA">
    Wikipedia: SCADA</a></p>

    <p>Some logs that an elementary SCADA system could generate.  The model
    is, once again, a hydroponics system. The hydroponics system has 2
    Raspberry Pis controlling various devices and this logs to a desktop.
    The desktop may send control commands. Various logs from both systems
    get sent to the logger to monitor and track events in these
    systems.</p>

    <p>Assume "hydro1" and "hydro2" are systems in a remote hydroponics
    garden with various measurement instrumentations. This remote system
    logs to a desktop inside the home.</p>

    <p>Commands the remote uses to start pumps and switchs get logged as
    well. This used "cmd=true&amp;pump1=ON&amp;host=hydro1" meaning this is
    a command that turns pump1 on and the host is hydro1.</p>

    <p>Some examples of data that appears in logs:</p>

    <ul>

         <li>A switch changing values ON/OFF.</li>

         <li>An instrument reporting temperature reading.</li>

         <li>A water level indicator reading too low or to high.</li>

         <li>A moisture level too low has triggered.</li>

         <li>A periodic report of temperature.</li>

    </ul>

    <p>All of the above and more could appear in your logs. The specific
    values in the logs must, of course, have appropriate values for that
    device.</p>

    <h2>The UNKNOWN state</h2>

    <p>The "UNKNOWN" value should apply to <i>every</i> device!  Devices
    can suffer all manner of reasons for refusing to work properly: water
    damage, physically damanged, wiring problems, aging, etc. A switch does
    not have a simple ON/OFF, but should actually use ON/OFF/UNKNOWN.</p>

     <h2>Notice your keywords</h2>

     <p>Keyword ease problems in interpreting log files. Log files can
     become easier to interpret if reasonable keywords and values
     describe each device. Humans have great linguistic abilities. Please
     allow your creations to communicate their reading
     with easily understood descriptions.</p>

     <p>Some suggestions for naming:</p>
        
            <table>
                <tr>
                    <td>Keyword</td>
                    <td>Meaning</td>
                </tr>
                <tr>
                    <td>device</td>
                    <td>Device name</td>
                </tr>
                <tr>
                    <td>state</td>
                    <td>Value for descrete devices: ON, OFF, UNKNOWN</td>
                </tr>
                <tr>
                    <td>temp</td>
                    <td>Temperature reading for analog temperature</td>
                </tr>
                <tr>
                    <td>host</td>
                    <td>Which system sent this data?</td>
                </tr>
                <tr>
                    <td>cmd</td>
                    <td>= req : A command request was sent. host=system performing request.<br/>
                    =req : tag=xyz...&amp;host=central</td>
                </tr>
                <tr>
                    <td>cmd</td>
                    <td>=rep : A command reply indicates acknowledgement. host=sys performing command.
                      A reply sends the tag of the command. Optionally the entire
                      original command may populate the command.
                      cmd=rep&amp;tag=xyz&amp;host=hygro1</td>
                 </tr>

             </table>

             <p>Devices in this example:</p>

             <ul>

                 <li>pumpWaterLevel = A water pump to maintain proper levels.</li>

                 <li>waterLevel = A floatation switch that detects water levels too high or too low.</li>

                 <li>tempIN, tempOUT = analog temperature measurements.</li>

             </ul>

        <h2>A Trivial Logging Example</h2>

        <p>Assume the following logs exist. (The comments are not part of the
        logs.)</p>

        <pre>
    # A periodic reading of water and temperature from several instruments
    2016-03-14T08:00:00.000    INFO    device=water01&amp;state=OFF&amp;host=hydro1
    2016-03-14T08:00:00.000    INFO    device=tempIN&amp;temp=72.3&amp;host=hydro1
    2016-03-14T08:00:00.000    INFO    device=tempOUT&amp;temp=69.2&amp;host=hydro1
    # Water level has gone too low
    2016-03-14T08:00:07.325    ERROR    device=water01&amp;state=LOW&amp;host=hydro1
    # Pump started to raise water level. A command was sent
    # pump01 request to start.
    2016-03-14T08:00:09.876    INFO    cmd=req&amp;tag=xyz&amp;device=pump01&amp;state=ON&amp;host=hydro1
    # Command started, remote sends reply. Note use of "tag"
    2016-03-14T08:00:09.876    INFO    cmd=rep&amp;tag=xyz&amp;host=hydro1
    # Water level back to normal and turn pump1 off.
    2016-03-14T08:05:05.325    INFO    device=water01&amp;state=OK&amp;host=hydro1
    # Command to turn pump01 off.
    2016-03-14T08:05:15.876    INFO    cmd=req&amp;tag=abc&amp;device=pump01&amp;state=OFF&amp;host=hydro1
    # Response: Pump01 starting to off state.
    2016-03-14T08:05:15.876    INFO    cmd=rep&amp;tag=abc&amp;host=hydro1
    # Periodic readings
    # One reading per device.
    2016-03-14T08:10:00.000    INFO    device=water01&amp;temp=71.2&amp;host=hydro1
    2016-03-14T08:10:00.000    INFO    device=pump01&amp;state=OFF&amp;host=hydro1
    2016-03-14T08:10:00.000    INFO    device=fan02&amp;state=OFF&amp;host=hydro1
    2016-03-14T08:10:00.000    INFO    device=temp04&amp;temp=71.1&amp;host=hydro1
    2016-03-14T08:10:00.000    INFO    device=temp03&amp;temp=70.5&amp;host=hydro1
        </pre>

        <p>Notice the uniformity of the above logs.</p>

        <ul>

            <li>One device per command. This eases analysis logic because
            parsing that one keyword allows easy processing of that one
            value.</li>

            <li>Each command request, "cmd=req&amp;tag=abc", has a tag. This
            ensures that the response with a command reply,
            "cmd=rep&amp;tab=abc", has been received by the remote.  The
            "cmd=rep&amp;abc" does <i>not</i> imply that the command was
            successfully completed, only that the remote received the
            command.</li>

            <li>The various instruments talk in their "native" representations.
            For instance, pumps belong to one of the ON, OFF or UNKNOWN states.
            A temperature measurement replies as "temp=65.2", etc. Your
            individual needs will, of course, vary.</li>

            <li>Macro commands could provide for a flurry of activity. An
            example of a macro command could be "circulate" wherein the pumps
            that circulate nutrient solutions activate and remain on the a pre
            determined period.  These may orginate either in the remote or
            central control. Macros remain beyond the ken of loggers except to
            record the issuance of the command itself. The logger simply
            monitors and records activity.</li>

        </ul>


        <h1>Troubleshooting</h1>

        TBD - installation
        Port issues.
        Permission denied.

        <h2>I get "permission denied" when I ...</h2>

        <p>Some part of your attempted operation tried to access
        areas protected by root access. Prefix you command with
        <code>sudo</code> and try again.</p>

        <h2>Undefined symbol: zmq_msg_gets</h2>

        <p>When starting logCollector, logCmd, ..., a bomb ending in
        <code>ImportError: ... undefined symbol: zmq_msg_gets</code>

        <p><code>sudo python</code> and <code>python</code> could be
        different python versions due to $PATH. Run this:<p>

        <pre>python -c 'import zmq; print(zmq)
        sudo python -c 'import zmq; print(zmq)
        </pre>

        <p>If the <code>import zmq</code> fails, please refer to
        the web. This happened to me and it took a while to straighten
        this out. I wish I could tell you what to do in this case,
        but I'm not sure myself what fixed the problem. Yuck!</p>

        <h1>ISO8601 - What IS this?</h1>

        <p><a href="https://en.wikipedia.org/wiki/ISO_8601">ISO8601</a>
        refers to an international standard for representation of
        dates and times for the exchange of date and time related
        data. The ISO8601 standard provide an unambiguous and well-defined
        method of representing dates and time.</p>

        <p>For purposes of simple log messaging, each individual
        log entry gets tags with the ISO8601 date-time when
        logCollector receives the log.</p>
        
        <p>Systems using multiple nodes
        all have logs time stamped by the logCollector and <i>not</i>
        by the times on each node. This avoids time synchronization
        problems of keeping all nodes in time sync. This design
        element will not work for all systems, but for the targeted
        audience, Raspberry Pi/Arduino/..., this should not
        pose a problem.</p>

        <p>A deviation from the ISO8601 standard: simple log messaging
        uses local time as defined by the logCollector node. The
        standard demands UTC time. This was deemed confusing for purposes
        of this application.</p>

        <p>Simple log messaging uses local time, and when daylight
        savings time switches, the timestamps follow system time.
        This means an hour may be repeated or ignored depending
        upon the time of year.</p>

        <h2>TBD - Coding for ISO8601,....</h2>


        <h1>Original Ideas: ZeroMQ</h1>

        <p>This code calls ZeroMQ, also known as 0MQ or zmq, with python
        bindings, PyZMQ, to build this logger.  The <a
        href="http://zeromq.org/intro:read-the-manual">The Asynchronous
    Client/Server Pattern</a> forms the basic idea of this logger. The full
ZeroMQ pattern implements bidirectional messages while the simple log messaging
app uses the direction only from processes to the loggerControler.</p>

        <p>The simple log messaging app implementation derives from the
        Asynchronous Client/Server Pattern  in <a
        href="http://www.zeromq.com">ZeroMQ</a>, p. 111:<br/><center><img
        src="./images/AsyncClientServer1.svg"/></center></p>

        <p>This illustration uses three clients that access the RaspPi Logger.
        In practice the actual system may have one or more RaspPi systems
        sending logs to the RaspPi Logging system. The senders of the logs may
        also live either on the same system as the RaspPi loggers or on another
        system entirely. Remote systems may communicate with the RaspPi Logger
        through wireless transmission or an ethernet cable.  How is <i>that</i>
        for flexibility?</p>

        <h1>The Simple Messaging System - A Larger Vision</h1>

        <p>Simple log messaging just starts a suite of applications
        that provide an easy way to communicate with multiple
        nodes, be they Raspberry Pi, Arguino, Beagle Board
        and even desktop linux systems.</p>

        <p>I started with a logging system because I believe that
        basically <i>every</i> process envisioned needs a decent
        logging system to develop, debug and deploy multiple
        node systems.</p>

        <p>I used the excellent ZeroMQ libraries because ZeroMQ
        offers and ease of use not found in most messaging systems.
        ZeroMQ was wrapped in python because python is arguably the
        language of applications in this targeted market.</p>

        <p>Most importantly, I wanted relatively new developers
        from the Maker movement to have visions of connection multiple
        nodes to form new and creative methodologies to implement
        their own visions.</p>

        <p>To fully use the power of ZeroMQ for messaging requires
        two more basic modules: a name server and a control module.</p>

        <h2>Simple Name Server</h2>

        <p>Maintaining multiple nodes with coordinated communications
        can be a nightmare unless proper tools exist to support
        general node communications.</p>

        <p>A name server maintains a dictionary of names and port numbers.
        An external node knows it must communicate with a named node, e.g., "logCollector", so it queries the name server. The name server replies to the
        "logCollector" with the the proper port. This dictionary should
        persist between reboots.</p>

        <h2>Simple Control</h2>

        <p>Supplying commands to nodes must exist in some way. A unified
        command processing should ease application requirements for
        developers.<p>

        <p>In industry an example of this would be called "<a href="https://en.wikipedia.org/wiki/SCADA">SCADA</a>" - Supervisory Control And Data Acquisition.
        SCADA provides a system for remote monitoring and control.
        While SCADA systems can become quite elaborate, most of our needs
        could be quite modest.</p>

        <h2>A human interface</h2>

        <p>One major issue with our control system is the human interface:
        "How do we display our data that allows use to properly
        control our remote applications?"</p>

        <p>Since my vision for this tool encompasses all Maker style computer
        projects, a general human interface may be too general to be of much
        use. Perhaps multiple ideas require mulitple solutions. And most
        certainly some people have their own strong ideas; requirement ideas
        that are most valid indeed.</p>

        <p>A general human interface cannot be force fitted to this
        tool set. This problem may be addressed much futher down
        the line.</p>


        <h1>TODO list</h1>

        <p>Non-trivial software always has something missing. The missing
        something differs from person to person, from user to user.
        An important item for one user exists as a distraction to another user.
        We all have our own view of reality.</p>

        <p>Some items I consider important:</p>

        <ul>

            <li>Security. No security currently exists. As more and more
            systems get into the field, security becomes important. Do you
            want your home infested by a hacker? Definitely needed.</li>

            <li>Docs for expanding log filtering.</li>

            <li>Speed increase. The current speed on my desktop
            of about 70,000 messages/second should handle all
            but the most demanding applications. Does this need attention?</li>

            <li>runTests.sh. This current test script detects only success
            or failure of a run and does not examine output. This needs
            upgrading. However, current, Apr, 2016, coverage is 92%.</li>

            <li>Database for logs. Is this necessary? Too complicated?</li>

            <li>Periodic log rollover. How large do logs get before
            the unwieldy size encumbers use? This obviously depends
            on what gets logged and user tolerance. Build a process
            that performs rollover periodically or by size?</li>

        </ul>

        <h1>Afterwords</h1>

        <p>I am reminded of the famous quote by <a href-"http://joearms.github.io/2013/05/31/a-week-with-elixir.html">Joe Armstrong</a>,
        creator of Erlang:</p>

        <center>
        <div style="width:300px;border:1px solid #cecece; padding:10px;">
            <blockquote>The Three Laws of Programming Language Design<br/><ul><li>What you get right, nobody mentions it.</li><li>What you get wrong, people bitch about.</li><li>What is difficult to understand you have to explain to people over and over again.</li></ul></blockquote>
            <div class="credit" style="text-align:center;">
                <cite><a href="http://joearms.github.io/2013/05/31/a-week-with-elixir.html">Joe Armstrong on designing Erlang</a></cite>
            </div>
        </div>
        </center>

        <h1>Links and References</h1>

        <p><cite>ZeroMQ</cite> by Pieter Hintjens. Published by O'Reillly Media
        Inc, 2013.  <a href="http://www.zeromq.com">ZeroMQ</a>. This book
        provides a detailed description of ZeroMQ with many examples.  ZeroMQ
        offers a toolkit and not a framework. ZeroMQ has been used by <a
        href="http://zeromq.org/intro:read-the-manual"> many companies</a> as a
        basis for a wide variety of product. Highly recommended. Their website
        provides a plethora of ideas and practical advice.</p>

        <h1>License</h1>

        <p>In the spirit of the originators of ZeroMQ, the iMatix corporation,
        the following constitutes the license agreement:</p>

        <p>The project license is specified in COPYING and COPYING.LESSER.</p>

        <p>The simple log messaging app is free software; you can redistribute
        it and/or modify it under the terms of the GNU Lesser General Public
        License (LGPL) as published by the Free Software Foundation; either
        version 3 of the License, or (at your option) any later version.</p>

        <p>As a special exception, the Contributors give you permission to link
        this library with independent modules to produce an executable,
        regardless of the license terms of these independent modules, and to
        copy and distribute the resulting executable under terms of your
        choice, provided that you also meet, for each linked independent
        module, the terms and conditions of the license of that module. An
        independent module is a module which is not derived from or based on
        this library.  If you modify this library, you must extend this
        exception to your version of the library.</p>

        <p>The simple log messaging app is distributed in the hope that it will
        be useful, but WITHOUT ANY WARRANTY; without even the implied warranty
        of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
        Lesser General Public License for more details.</p>


        <h1>Additional Relevant material</h1>

        <h2>ISO 8601 Notes</h2>
        <p>What do I need, <i>EXACTLY</i>?</p>
        <ol>
            <li>Find local time with msec. (Could be tuple format)</li>
            <li>Convert local MS to ISO8601 display format</li>
            <li>Get milliseconds from ISO8601 display</li>
        </ol>

        <p><b>USE THIS!</b></p>
        <pre>
import datetime
import time

"""
    Illustrate multiple conversions of timestamps

    On the remote system:
    Obtain the local time with millisecond precision.
    Convert local time to display format with local timezone.
    
    This time in display format gets placed into logger
    Now convert the display formatted time into seconds
    since the epoch.
""" 

unixNow = time.time()
now = datetime.datetime.fromtimestamp(unixNow)
print 'unix now:%f'% unixNow
print 'now=%s' % str(now)
nowStr = now.strftime("%Y-%m-%dT%H:%M:%S.%f")
print 'nowStr = %s' % nowStr

#To get now to a tuple:
nowTuple = datetime.datetime.strptime(nowStr, "%Y-%m-%dT%H:%M:%S.%f")

print 'nowTuple:' + str(nowTuple)

secEpoch = time.mktime(nowTuple.timetuple()) + 1.0e-6*nowTuple.microsecond
print 'secEpoch: %s' % secEpoch
        </pre>
        <p>With output:</p>
        <pre>
python time1.py
unix now:1458147132.109625
now=2016-03-16 09:52:12.109625
nowStr = 2016-03-16T09:52:12.109625
nowTuple:2016-03-16 09:52:12.109625
secEpoch: 1458147132.11
        </pre>

        <p>ISO 8601 formatting: https://docs.python.org/2/library/datetime.html
        datetime.isoformat() returns a string in date time in ISO 8601 format:</p>
            <pre>
datetime.datetime.strptime( "2007-03-04T21:08:12", "%Y-%m-%dT%H:%M:%S" )
datetime.datetime(2007, 3, 4, 21, 8, 12)
            </pre>
Now: time.time()  in floating point seconds.

<h2>To get a now ISO8601 local time string: </h2>
<pre>
now = datetime.datetime.now()
print 'now=%s' &amp; str(now)
nowStr = datetime.datetime.now().strftime("%Y-%m-%dT%H:%M:%S.%f")
print 'nowStr = %s' &amp; nowStr

#To get now to a tuple:
nowTuple = datetime.datetime.strptime(nowStr, "%Y-%m-%d %H:%M:%S.%f")

print 'nowTuple:' + str(nowTuple)

msSinceEpoch = time.mktime(nowTuple.timetuple()) + 1.0e-6*nowTuple.microsecond
</pre>

<pre>
nowDT = datetime.datetime.strptime('2016-03-16T08:47:12.34', "%Y-%m-%dT%H:%M:%S.%f")
nowDT
datetime.datetime(2016, 3, 16, 8, 47, 12, 340000)
</pre>

<p>Current local time to milli sec since epoch:</p>
<pre>
from datetime import datetime
from time import mktime

dt = datetime.now()
sec_since_epoch = mktime(dt.timetuple()) + dt.microsecond/1000000.0

millis_since_epoch = sec_since_epoch * 1000
</pre>

<p>Some more conversions:</p>
<pre>
>>> import datetime
>>> import time
>>> import calendar

>>> #your datetime object
>>> now = datetime.datetime.now()
>>> now
datetime.datetime(2013, 3, 19, 13, 0, 9, 351812)

>>> #use datetime module's timetuple method to get a `time.struct_time` object.[1]
>>> tt = datetime.datetime.timetuple(now)
>>> tt
time.struct_time(tm_year=2013, tm_mon=3, tm_mday=19, tm_hour=13, tm_min=0, tm_sec=9,     tm_wday=1, tm_yday=78, tm_isdst=-1)

>>> #If your datetime object is in utc you do this way. [2](see the first table on docs)
>>> sec_epoch_utc = calendar.timegm(tt) * 1000
>>> sec_epoch_utc
1363698009

>>> #If your datetime object is in local timeformat you do this way
>>> sec_epoch_loc = time.mktime(tt) * 1000
>>> sec_epoch_loc
1363678209.0
</pre>


    </body>

</html>
        <h2><b>A LONG LIST OF MISC STATEMENTS</b></h2>
        <ul>


            <li>A run-time replacement for debuggers.</li>

            <li>An opportunity to clarify operational systems; a lens into
            current system details.</li>

            <li>An easy way to provide monitoring for multiple 
            systems such as Raspberry Pi or Arduinos.</li>

            <li>Tracking of remote systems in an orderly manner that
            facilitates data mining techniques.</li>

            <li>A small and simple to use technique easily downloaded
            and installed. The use in current applications should
            present few problems.</li>

            <li>Increased awareness of problems.</li>

            <li>Fast detection of outages and system problems.</li>

            <li>A centralized repository for system information.</li>

            <li>An invaluable tool to detect problems on installed
            systems.</li>

            <li>A aid to understanding the flow of control of an
            application. Non-trivial systems with multiple SOCs
            provide fertile grounds for timing and dependency problems.</li>

            <li>An aid for debugging before a system gets shipped.
            Logs can significantly enhance other development tools.</li>

            <li>By logging every request, analysis can provide busiest times,
            most commonly used commands, etc.</li>

            <li>After-the-fact forensic analysis relies on decent logging
            to discover and solve problems.</li>

            <li>Careful: Logging can become an addiction whose value is rarely
            justified.  For every situation where you can log gratuitously,
            it's better to collect targeted information and send it where you
            need it to go.</li>

            <li>If your app crashes, any buffered information is lost. If
            logs are sent to a logging task, that logging task can likely report
            up the last log reported.</li>

            <li>At first you may have only an inkling of what logs
            provide valuable information. Only after use and analysis
            will clarity emerge.</li>

            <li>Appreciating the significance of logging takes practive.</li>

            <li>Capturing stack traces. Multi-line output may special logging
            consideration.</li>

            <li>Profiling information. By tracking the various states of
            a running system, bottlenecks may present themselves.</li>

            <li>(Future) Dynamically modify the log level: turn DEBUG on and off at will.</li>

            <li>Write logging code anticipating that you may one day have to
            debug a situation where ALL you have is the log file, and doing it
            right may be the difference between getting fired and getting
            promoted.</li>

            <li>When problems arise on a running system, logs are likely your
            <i>only</i> information source. The assist in reproducing erroneous
            cases. If you can reproduce it, you can find a way to debug
            it.</li>
            
            <li>ISO8601 has notation for periodic events! This
            may also be used for intervening time between two time points.
            See https://en.wikipedia.org/wiki/ISO_8601 "Time intervals"</li>
        </ul>
